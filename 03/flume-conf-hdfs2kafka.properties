# ------------------- 定义数据流----------------------
# source的名字
flume2kafka_agent.sources = source_from_HDFS 
# channels的名字，建议按照type来命名
flume2kafka_agent.channels = mem_channel  
# sink的名字，建议按照目标来命名
flume2kafka_agent.sinks = kafka_sink

#auto.commit.enable = true  

## kerberos config ##  
#flume2kafka_agent.sinks.kafka_sink.hdfs.kerberosPrincipal = flume/datanode2.hdfs.alpha.com@OMGHADOOP.COM  
#flume2kafka_agent.sinks.kafka_sink.hdfs.kerberosKeytab = /root/apache-flume-1.6.0-bin/conf/flume.keytab   


#-------- Source相关配置-----------------
# 定义消息源类型
# For each one of the sources, the type is defined  
flume2kafka_agent.sources.source_from_HDFS.type = exec
flume2kafka_agent.sources.source_from_HDFS.channels = mem_channel  
flume2kafka_agent.sources.source_from_HDFS.command = cat ./logs

# 配置消费的kafka groupid
flume2kafka_agent.sources.source_from_HDFS.kafka.consumer.group.id = flumetest

#---------kafka Sink 相关配置------------------
# The channel can be defined as follows.  
flume2kafka_agent.sinks.kafka_sink.type = org.apache.flume.sink.kafka.KafkaSink
flume2kafka_agent.sinks.kafka_sink.kafka.bootstrap.servers = master:9092

# 指定sink需要使用的channel的名字,注意这里是channel
#Specify the channel the sink should use 
flume2kafka_agent.sinks.kafka_sink.channel = mem_channel 

#File size to trigger roll, in bytes (0: never roll based on file size)
flume2kafka_agent.sinks.kafka_sink.kafka.topic = mtopic  
flume2kafka_agent.sinks.kafka_sink.kafka.flumeBatchSize = 100   



#------- memoryChannel相关配置-------------------------
# channel类型
# Each channel's type is defined.  
flume2kafka_agent.channels.mem_channel.type = memory  
# Other config values specific to each type of channel(sink or source)  
# can be defined as well  
# channel存储的事件容量
# In this case, it specifies the capacity of the memory channel  
flume2kafka_agent.channels.mem_channel.capacity = 100000  
# 事务容量
flume2kafka_agent.channels.mem_channel.transactionCapacity = 10000  
